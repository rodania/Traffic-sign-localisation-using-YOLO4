{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model & image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "yolo_model = cv2.dnn.readNetFromDarknet('trained_model/cov_yolov4.cfg','trained_model/cov_yolov4_2000.weights')\n",
    "\n",
    "# Get all layers from the yolo network\n",
    "# Loop and find the last layer (output layer) of the yolo network \n",
    "yolo_layers = yolo_model.getLayerNames()\n",
    "yolo_output_layer = [yolo_layers[layer[0] - 1] for layer in yolo_model.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test image paths\n",
    "testImges = open('yolo/darknet/sign_data/test.txt', 'r')\n",
    "testImges = [i for i in testImges.read().split('\\n')]\n",
    "\n",
    "# assign class label\n",
    "class_labels = ['traffic sign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy ground truth files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get path of annotation test file\n",
    "imgPath = 'yolo/darknet/sign_data/images/'\n",
    "txt = [i.split('/')[-1] for i in testImges]\n",
    "txtFiles = [imgPath+i.split('.')[0]+'.txt' for i in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy ground truth files of test images into mAP-master directory\n",
    "dest = 'test_model/mAP-master/mAP-master/input/ground-truth/'\n",
    "for file in txtFiles:\n",
    "    name = file.split('/')[-1]\n",
    "    shutil.copyfile(file, dest+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path of image test files\n",
    "imgPath = 'yolo/darknet/sign_data/images/'\n",
    "txt = [i.split('/')[-1] for i in testImges]\n",
    "imgFiles = [imgPath+i.split('.')[0]+'.ppm' for i in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy img into map test input directory\n",
    "dest = 'test_model/mAP-master/mAP-master/input/images-optional/'\n",
    "for file in imgFiles:\n",
    "    name = file.split('/')[-1]\n",
    "    shutil.copyfile(file, dest+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the predicted annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_anno(imgPath, savePath):\n",
    "    \n",
    "    # load test image \n",
    "    img =cv2.imread(imgPath)\n",
    "    imgName = imgPath.split('/')[-1].split('.')[0]    \n",
    "\n",
    "    # construct a blob for img\n",
    "    imgBlob = cv2.dnn.blobFromImage(img, 0.003922, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    # get image shape\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "\n",
    "    # input preprocessed blob into the model\n",
    "    yolo_model.setInput(imgBlob)\n",
    "    # get prediction\n",
    "    obj_detection_layers = yolo_model.forward(yolo_output_layer)\n",
    "    \n",
    "    # create empty lists to save parameters\n",
    "    class_ids_list = []\n",
    "    boxes_list = []\n",
    "    confidences_list = []\n",
    "    yolo_box = []\n",
    "\n",
    "    # loop over each of the layer outputs\n",
    "    for object_detection_layer in obj_detection_layers:\n",
    "        # loop over the detections\n",
    "        for object_detection in object_detection_layer:\n",
    "\n",
    "            # obj_detections[1 to 4] => will have the two center points, box width and box height\n",
    "            # obj_detections[5] => will have scores for all objects within bounding box\n",
    "            all_scores = object_detection[5:]\n",
    "            predicted_class_id = np.argmax(all_scores)\n",
    "            prediction_confidence = all_scores[predicted_class_id]\n",
    "\n",
    "            # take only predictions with confidence more than 60%\n",
    "            if prediction_confidence > 0.60:\n",
    "                #get the predicted label\n",
    "                predicted_class_label = class_labels[predicted_class_id]\n",
    "                #obtain the bounding box co-oridnates for actual image from resized image size\n",
    "                bounding_box = object_detection[0:4] * np.array([width, height, width, height])\n",
    "                (box_center_x_pt, box_center_y_pt, box_width, box_height) = bounding_box.astype(\"int\")\n",
    "                start_x_pt = int(box_center_x_pt - (box_width / 2))\n",
    "                start_y_pt = int(box_center_y_pt - (box_height / 2))\n",
    "\n",
    "                # save class id, start x, y, width & height, confidences in a list\n",
    "                # make sure to pass confidence as float and width and height as integers\n",
    "                class_ids_list.append(predicted_class_id)\n",
    "                confidences_list.append(float(prediction_confidence))\n",
    "                boxes_list.append([start_x_pt, start_y_pt, int(box_width), int(box_height)])\n",
    "                yolo_box.append([box_center_x_pt, box_center_y_pt, int(box_width), int(box_height)])\n",
    "                \n",
    "    # apply non-maxima suppression\n",
    "    max_value_ids = cv2.dnn.NMSBoxes(boxes_list, confidences_list, 0.5, 0.4)\n",
    "    \n",
    "    # create an empty list to store sign annotation inside\n",
    "    text = []\n",
    "    \n",
    "    # loop inside max_value_ids\n",
    "    for max_valueid in max_value_ids:\n",
    "        max_class_id = max_valueid[0]\n",
    "        box = yolo_box[max_class_id]\n",
    "        centre_x_pt = box[0]/ width\n",
    "        centre_y_pt = box[1]/ height\n",
    "        box_width = box[2]/ width\n",
    "        box_height = box[3]/ height\n",
    "\n",
    "        #get the predicted class id and label\n",
    "        predicted_class_id = class_ids_list[max_class_id]\n",
    "        predicted_class_label = class_labels[predicted_class_id]\n",
    "        prediction_confidence = confidences_list[max_class_id]\n",
    "\n",
    "        # save yolo annotation for each sign and store it in a list \n",
    "        line = \"{} {} {} {} {} {}\".format(predicted_class_id, prediction_confidence, centre_x_pt, centre_y_pt, box_width, box_height)\n",
    "        text.append(line)\n",
    "            \n",
    "    # Write file\n",
    "    filePath = savePath + imgName + '.txt'\n",
    "    with open(filePath, 'w') as file:\n",
    "        for item in text:\n",
    "            file.writelines(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = 'yolo/darknet/'\n",
    "savePath = 'test_model/mAP-master/mAP-master/input/detection-results/'\n",
    "\n",
    "for img in testImges:\n",
    "    save_anno(basePath + img, savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
